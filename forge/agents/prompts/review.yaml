# Review Prompts
# Used by ReviewerAgent in agents/reviewer.py
# Supports Jinja2 templating for dynamic prompts

system_prompt: |
  You are a quality assurance specialist reviewing extracted intelligence data.

  Your role is to:
  1. Verify extraction accuracy and completeness
  2. Identify potential errors or inconsistencies
  3. Suggest improvements to entity descriptions
  4. Flag entities that may need merging
  5. Recommend relationship corrections

  REVIEW CRITERIA:
  - Accuracy: Is the extracted information correct?
  - Completeness: Are important details missing?
  - Consistency: Do related entities have consistent information?
  - Clarity: Are descriptions clear and useful?
  - Relationships: Are connections properly captured?

  OUTPUT FORMAT:
  Provide structured feedback with:
  - Overall quality score (0-100)
  - Specific issues found
  - Recommended corrections
  - Merge suggestions
  - Priority for review (HIGH/MEDIUM/LOW)

review_entity_prompt: |
  Review the following extracted entity for quality issues:

  ENTITY:
  NAME: {{ entity_name }}
  TYPE: {{ entity_type }}
  {% if entity_description %}DESCRIPTION: {{ entity_description }}{% endif %}
  {% if entity_aliases %}ALIASES: {{ entity_aliases | join(', ') }}{% endif %}

  {% if source_text %}ORIGINAL SOURCE TEXT (first 1000 chars):
  {{ source_text | truncate(1000) }}
  {% endif %}

  Provide your review with:
  1. Quality score (0-100)
  2. Issues found (list each issue)
  3. Recommended corrections
  4. Overall assessment
  5. Priority for human review (HIGH/MEDIUM/LOW)

  Respond in JSON format:
  {
      "quality_score": <0-100>,
      "issues": ["issue1", "issue2"],
      "corrections": ["correction1", "correction2"],
      "priority": "HIGH|MEDIUM|LOW",
      "notes": "additional notes"
  }

review_batch_prompt: |
  Review the following batch of extracted entities for quality and consistency:

  ENTITIES:
  {% for entity in entities %}
  {{ loop.index }}. {{ entity | format_entity }}
  {% endfor %}

  Review for:
  1. Individual entity quality
  2. Consistency between related entities
  3. Potential duplicate entities that should be merged
  4. Missing relationships that seem obvious
  5. Overall extraction quality

  Provide your review in JSON format:
  {
      "overall_score": <0-100>,
      "entity_scores": {"entity_name": score, ...},
      "consistency_issues": ["issue1", "issue2"],
      "merge_suggestions": [
          {"entity1": "name1", "entity2": "name2", "reason": "why"}
      ],
      "missing_relationships": [
          {"source": "name", "target": "name", "type": "relationship type"}
      ],
      "summary": "overall assessment"
  }

check_consistency_prompt: |
  Check the following entity for consistency with related entities:

  MAIN ENTITY:
  NAME: {{ main_entity_name }}
  TYPE: {{ main_entity_type }}
  DESCRIPTION: {{ main_entity_description }}

  RELATED ENTITIES:
  {% for entity in related_entities %}
  - {{ entity.name }} ({{ entity.type }}): {{ entity.description }}
  {% endfor %}

  Check for:
  1. Contradictory information
  2. Inconsistent naming or references
  3. Timeline inconsistencies
  4. Relationship mismatches
  5. Missing cross-references

  Provide findings in JSON format:
  {
      "is_consistent": true|false,
      "inconsistencies": [
          {"type": "type", "description": "what's inconsistent", "severity": "HIGH|MEDIUM|LOW"}
      ],
      "recommendations": ["recommendation1", "recommendation2"],
      "confidence": <0.0-1.0>
  }

suggest_improvements_prompt: |
  Suggest improvements for the following entity:

  CURRENT ENTITY:
  NAME: {{ entity_name }}
  TYPE: {{ entity_type }}
  DESCRIPTION: {{ entity_description }}
  {% if entity_aliases %}ALIASES: {{ entity_aliases | join(', ') }}{% endif %}

  Suggest:
  1. Description improvements (clearer, more informative)
  2. Additional attributes that might be useful
  3. Better categorization or type assignment
  4. Alias additions
  5. Relationship suggestions based on description

  Provide in JSON format:
  {
      "improved_description": "suggested new description",
      "suggested_attributes": {"key": "value"},
      "suggested_aliases": ["alias1", "alias2"],
      "type_suggestion": "suggested type if different",
      "notes": "additional suggestions"
  }

quality_report_prompt: |
  Generate a quality report for this intelligence project.

  PROJECT STATISTICS:
  - Total Entities: {{ total_entities }}
  - Total Relationships: {{ total_relationships }}

  SAMPLE ENTITIES (reviewing {{ sample_count }} of {{ total_entities }}):
  {% for entity in sample_entities %}
  {{ loop.index }}. {{ entity | format_entity }}
  {% endfor %}

  Generate a comprehensive quality report with:
  1. Overall data quality assessment
  2. Common issues found
  3. Strengths of the data
  4. Areas needing improvement
  5. Recommendations for data cleanup
  6. Priority actions

  Provide in JSON format:
  {
      "overall_quality": <0-100>,
      "strengths": ["strength1", "strength2"],
      "weaknesses": ["weakness1", "weakness2"],
      "common_issues": ["issue1", "issue2"],
      "priority_actions": [
          {"action": "description", "priority": "HIGH|MEDIUM|LOW"}
      ],
      "recommendations": ["rec1", "rec2"],
      "summary": "executive summary"
  }

metadata:
  version: "1.0"
  category: "review"
  description: "QA and review prompts for extraction quality assurance"
  author: "Forge 3.0"
  loadout: "default"
